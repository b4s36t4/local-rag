---
import Layout from "../layouts/Layout.astro";
import { RenderMessageList } from "../components/RenderMessageList.tsx";
import { Paperclip } from "lucide-react";
---

<Layout title="ChatLLM">
  <div
    class="mx-[10%] max-h-[calc(100vh-150px)] mt-10 border-2 flex flex-col rounded-md border-slate-300"
  >
    <RenderMessageList client:load />

    <div class="flex flex-col m-2 relative">
      <div
        class="flex bg-red-100 p-1 controlled-border border-2 border-b-0 rounded-tr-lg rounded-tl-lg flex-col"
      >
        <div class="flex">
          <p class="text-sm">
            Model Selected: <span class="font-bold" id="selectedModel"></span>
          </p>
          <button id="loadOrDownload" class="ml-4 p-0 m-0 text-blue-600"
          ></button>
        </div>
        <div>
          <p class="text-sm">
            Agent: <span class="font-bold" id="selectedAgent">None</span>
          </p>
        </div>
      </div>
      <div
        class="flex border-b-2 border-l-2 border-r-2 overflow-scroll controlled-border rounded-br-lg rounded-bl-lg"
      >
        <textarea
          placeholder="Enter Message"
          id="promptInput"
          class="w-[85%] outline-none p-2 flex-1"
          rows="3"
          style="resize: none;"></textarea>
        <div class="flex mx-4 py-4 items-center space-x-1">
          <button
            ><Paperclip
              className="mr-4"
              role="button"
              client:visible
              id="attachmentPickerBtn"
            />
          </button>

          <input
            type="file"
            accept="text/pdf"
            class="hidden"
            id="attachmentPicker"
          />
          <button
            class="h-full bg-slate-200 mr-4 rounded-lg p-4 my-auto"
            id="sendChat">Send</button
          >
        </div>
      </div>
    </div>
  </div>
</Layout>

<style>
  #statusTooltip {
    width: max-content;
    position: absolute;
    top: 0;
    left: 0;
    background: #222;
    color: white;
    font-weight: bold;
    padding: 5px;
    border-radius: 4px;
    font-size: 90%;
  }

  :root {
    --input-border-color: rgb(55 65 81 / var(--tw-border-opacity));
  }

  .controlled-border {
    border-color: var(--input-border-color);
  }

  .shiki {
    @apply overflow-x-auto rounded-lg p-4;
  }
</style>

<script>
  import {
    hasModelInCache,
    prebuiltAppConfig,
    CreateMLCEngine,
    MLCEngine,
    type InitProgressCallback,
    type ChatCompletionMessageParam,
  } from "@mlc-ai/web-llm";
  import { chatStore, newMessageStore } from "../store/chat";
  import { modelStore } from "../store/modelStore";
  import { agentStore } from "../store/agent";
  import Toastify from "toastify-js";
  import { toCompletionMessage } from "../utils/message";

  import { EmbedDB } from "../embed/db";
  import { WorkerPostTypes } from "../const";
  import { getAgentInstance } from "../utils/agent";
  import { ModelInstance } from "../agents/BaseInstance";

  let model: MLCEngine;

  window.MODEL_LOADED = false;
  window.CHAT_PDF = false;

  const embedWorker = new Worker(
    new URL("../embed/worker.ts", import.meta.url),
    { type: "module" }
  );
  const { pushMessage } = chatStore.getState();

  const db = await EmbedDB.getDB();
  window.db = db;

  let currentAgent: string | null = agentStore.getState().selectedAgentId;
  let currentAgentInstance: ModelInstance | null = null;
  const loadAgent = () => {
    currentAgentInstance = getAgentInstance(currentAgent ?? "", {
      model,
      worker: embedWorker,
    });
    agentStore.setState({
      selectedAgentInstance: currentAgentInstance,
    });
  };

  const currentAgentElement = document.getElementById("selectedAgent");

  {
    // Keep track of the current live agent
    currentAgentElement!.innerText = currentAgent ?? "";

    console.log(
      "%c[AGENT]",
      "background-color: wheat;padding:2px;color: black",
      "Current agent is",
      currentAgent
    );

    agentStore.subscribe((store) => {
      currentAgent = store.selectedAgentId;
      currentAgentInstance = store.selectedAgentInstance!;

      if (!!currentAgent) {
        currentAgentElement!.innerText = currentAgent;
      }
    });
  }

  const attachmentInput = document.getElementById(
    "attachmentPicker"
  ) as HTMLInputElement;
  const attachmentPickerBtn = document.getElementById("attachmentPickerBtn");

  let currentRunningToast: any = null;

  {
    // Attachment Handlers
    attachmentPickerBtn?.addEventListener("click", () => {
      attachmentInput?.click();
    });

    attachmentInput?.addEventListener("change", async function () {
      const file = this.files?.item(0);
      if (!file) {
        return;
      }

      if (!currentAgentInstance) {
        await startModel();
      }

      currentAgentInstance?.loadFile(file);

      Toastify({ text: "PDF Embedding completed", duration: 1000 }).showToast();
    });
  }

  {
    // Worker Listener
    embedWorker.addEventListener("message", async (event) => {
      const isProgressEvent = event.data?.status === "progress";
      const isProgressDone = event.data?.status === "ready";

      if (isProgressEvent && currentRunningToast === null) {
        currentRunningToast = Toastify({
          text: "Loading embed Model...",
          duration: -1,
        });
        currentRunningToast?.showToast();
        return;
      }

      if (isProgressDone) {
        currentRunningToast.hideToast();

        Toastify({
          text: "Embedding model loaded!",
          duration: 1000,
        }).showToast();
      }

      if (event.data?.type === WorkerPostTypes.embedQuestion) {
        const context = currentAgentInstance?.search(event.data.data);
        if (!context) {
          return;
        }

        const contextData = context.neighbors
          .map((result) => result.title)
          .join("\n\n");
        currentAgentInstance?.ask(event.data.payload, contextData, enableSend);
      }
    });
  }

  // Updateable Text fields
  const modelText = document.getElementById("selectedModel");
  const modelStatus = document.getElementById("loadOrDownload");

  const sendButton = document.getElementById("sendChat");
  const input = document.getElementById("promptInput") as HTMLInputElement;

  let selectedModel = null;

  if (!modelStore.getState().selectedModel) {
    // Get the model which requires the least ram, so trying is easy
    selectedModel = prebuiltAppConfig.model_list.sort().at(-1);

    // selectedModel!.overrides = {
    //   sliding_window_size: 1024,
    //   temperature: 0.5,
    //   top_p: 0.3,
    //   attention_sink_size: 4,
    //   frequency_penalty: 0.3,
    //   presence_penalty: 0.5,
    //   repetition_penalty: 0.2,
    // };

    modelStore.setState({ selectedModel: selectedModel });
  } else {
    selectedModel = modelStore.getState().selectedModel;
  }

  selectedModel!.overrides = {
    // sliding_window_size: 1024,
    temperature: 0.5,
    top_p: 0.3,
    attention_sink_size: 4,
    frequency_penalty: 0.3,
    presence_penalty: 0.5,
    repetition_penalty: 0.2,
    context_window_size: 1024,
  };
  // Check weather the model is already downloaded
  const isSelectedModelAvailable = await hasModelInCache(
    selectedModel?.model_id ?? "",
    prebuiltAppConfig
  );

  const checkForGPU = async () => {
    const isGPUAvailable = "gpu" in window.navigator;
    const isGPUAdapoterAvailable =
      isGPUAvailable && (await (window.navigator as any).gpu.requestAdapter());
    if (!isGPUAvailable || !isGPUAdapoterAvailable) {
      sendButton!.textContent = "Not available";
      modelStatus!.innerHTML = "Unavailable";
      return false;
    }

    return true;
  };

  // Disable send button while model loading
  const disableSend = () => {
    if (sendButton) {
      sendButton.setAttribute("disabled", "true");
      sendButton.textContent = "Loading...";
    }
  };

  // enable send button when mode is loaded
  const enableSend = () => {
    if (sendButton) {
      sendButton.removeAttribute("disabled");
      sendButton.textContent = "Send";
    }
  };

  // Callback to handle the progress event
  const handleProgress: InitProgressCallback = function (report) {
    if (report.progress === 1) {
      enableSend();
      modelStatus!.innerText = "Loaded";
      return;
    }
    const progress = Math.round(report.progress * 100);
    if (modelStatus) {
      modelStatus.innerText = `${progress}% of 100%`;
    }
  };

  const startModel = async function () {
    if (window.MODEL_LOADED) {
      return;
    }
    model = await CreateMLCEngine(
      selectedModel?.model_id ?? "",
      {
        logLevel: "DEBUG",
        initProgressCallback: handleProgress,
        appConfig: prebuiltAppConfig,
      },
      {
        sliding_window_size: 512,
        context_window_size: -1,
        // temperature: 0.2,
        attention_sink_size: 4,
        // frequency_penalty: 0.6,
        // presence_penalty: 0.5,
        // repetition_penalty: 0.3,
      }
    );

    loadAgent();

    window.MODEL_LOADED = true;
  };

  const loadModel = async () => {
    modelStatus!.addEventListener("click", async function (event) {
      event.preventDefault();
      disableSend();

      startModel();
    });

    const resetInputText = async () => {
      input.value = "";
    };

    sendButton?.addEventListener("click", async function () {
      const question = input.value;
      const questionMessage = toCompletionMessage(question);

      disableSend();
      if (question.trim().length === 0) {
        alert("Please ask what you want?!");
        return;
      }
      if (!window.MODEL_LOADED) {
        disableSend();
        await startModel();
        window.MODEL_LOADED = true;
      }

      if (currentAgent) {
        embedWorker.postMessage({
          type: WorkerPostTypes.embedQuestion,
          data: question,
        });
        pushMessage(questionMessage);
        resetInputText();
        return;
      }

      pushMessage(questionMessage);
      resetInputText();

      const output = await model.chat.completions.create({
        messages: chatStore.getState().messages,
        n: 1,
        stream_options: { include_usage: true },
        stream: true,
        // max_tokens: 512,
        temperature: 0.2,
      });

      const message: ChatCompletionMessageParam = {
        content: "",
        role: "assistant",
      };

      newMessageStore.setState({ generating: true });

      for await (const chunk of output) {
        if (
          chunk.choices.length === 0 ||
          chunk.choices[0]?.finish_reason === "stop"
        ) {
          break;
        }

        const chunkMessage = chunk.choices[0].delta.content;
        if (!chunkMessage) {
          break;
        }
        message["content"]! += chunkMessage;

        newMessageStore.setState({ message: message["content"] ?? "" });

        // Indicating that generation has stopped
      }

      pushMessage(message);

      newMessageStore.setState({ generating: false, message: "" });
      enableSend();
    });
  };

  if (modelText) {
    modelText.innerText = selectedModel?.model_id ?? "";
  }

  if (modelStatus && (await checkForGPU())) {
    modelStatus.innerText = isSelectedModelAvailable ? "Load" : "Download";
    modelStatus.title = isSelectedModelAvailable
      ? "Load the model to start LLM"
      : "Download the model and start LLM";

    loadModel();
  }
</script>
